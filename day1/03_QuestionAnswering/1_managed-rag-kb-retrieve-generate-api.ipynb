{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Q&A application using Knowledge Bases for Amazon Bedrock - RetrieveAndGenerate API\n",
    "### Context\n",
    "\n",
    "With knowledge bases, you can securely connect foundation models (FMs) in Amazon Bedrock to your company\n",
    "data for Retrieval Augmented Generation (RAG). Access to additional data helps the model generate more relevant,\n",
    "context-speciﬁc, and accurate responses without continuously retraining the FM. All information retrieved from\n",
    "knowledge bases comes with source attribution to improve transparency and minimize hallucinations. For more information on creating a knowledge base using console, please refer to this [post](!https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html).\n",
    "\n",
    "In this notebook, we will dive deep into building Q&A application using `RetrieveAndGenerate` API provided by Knowledge Bases for Amazon Bedrock. This API will query the knowledge base to get the desired number of document chunks based on similarity search, integrate it with Large Language Model (LLM) for answering questions.\n",
    "\n",
    "\n",
    "### Pattern\n",
    "\n",
    "We can implement the solution using Retreival Augmented Generation (RAG) pattern. RAG retrieves data from outside the language model (non-parametric) and augments the prompts by adding the relevant retrieved data in context. Here, we are performing RAG effectively on the knowledge base created in the previous notebook or using console. \n",
    "\n",
    "### Pre-requisite\n",
    "\n",
    "Before being able to answer the questions, the documents must be processed and stored in knowledge base.\n",
    "\n",
    "1. Load the documents into the knowledge base by connecting your s3 bucket (data source). \n",
    "2. Ingestion - Knowledge base will split them into smaller chunks (based on the strategy selected), generate embeddings and store it in the associated vectore store.\n",
    "\n",
    "![data_ingestion.png](./images/data_ingestion.png)\n",
    "\n",
    "\n",
    "#### Notebook Walkthrough\n",
    "\n",
    "For our notebook we will use the `RetreiveAndGenerate API` provided by Knowledge Bases for Amazon Bedrock which converts user queries into\n",
    "embeddings, searches the knowledge base, get the relevant results, augment the prompt and then invoking a LLM to generate the response. \n",
    "\n",
    "We will use the following workflow for this notebook. \n",
    "\n",
    "![retrieveAndGenerate.png](./images/retrieveAndGenerate.png)\n",
    "\n",
    "\n",
    "### USE CASE:\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "In this example, you will use several years of Amazon's Letter to Shareholders as a text corpus to perform Q&A on. This data is already ingested into the knowledge base. You will need the `knowledge base id` and `model ARN` to run this example. We are using `Anthropic Claude Instant` model for generating responses to user questions.\n",
    "\n",
    "### Python 3.10\n",
    "\n",
    "⚠  For this lab we need to run the notebook based on a Python 3.10 runtime. ⚠\n",
    "\n",
    "### Setup\n",
    "\n",
    "Install following packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install boto3==1.33.2 --force-reinstall --quiet\n",
    "%pip install botocore==1.33.2 --force-reinstall --quiet\n",
    "%pip install opensearch-py\n",
    "%pip install requests-aws4auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper functions for bedrock agent & knowledge base creation\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import boto3\n",
    "import botocore\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "opensearch_serverless_client = boto3.client('opensearchserverless')\n",
    "agent_client = boto3.client(\"bedrock-agent\")\n",
    "lambda_client = boto3.client('lambda')\n",
    "iam = boto3.client('iam')\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def get_agent_id_and_s3_bucket_name_from_payload(props):\n",
    "    \n",
    "    print(f'Properties: {props}')\n",
    "    agent_id = ''\n",
    "    s3_bucket_name = ''\n",
    "    \n",
    "    for prop in props:\n",
    "        print(prop)\n",
    "        if prop['name'] == 'agentId':\n",
    "            agent_id = prop['value']\n",
    "        elif prop['name'] == 's3KnowledgeBaseBucketName':\n",
    "            s3_bucket_name = prop['value']\n",
    "            \n",
    "    return s3_bucket_name, agent_id\n",
    "\n",
    "\n",
    "def create_encryption_policy(agent_id):\n",
    "    \"\"\"Creates an encryption policy that matches all collections beginning with collection-\"\"\" + agent_id + \"\"\"\"\"\"\n",
    "    try:\n",
    "        response = opensearch_serverless_client.create_security_policy(\n",
    "            description=f'Encryption policy created by an agent with id {agent_id}.',\n",
    "            name=f'agent-{agent_id}-policy',\n",
    "            policy=\"\"\"\n",
    "                {\n",
    "                    \\\"Rules\\\":[\n",
    "                        {\n",
    "                            \\\"ResourceType\\\":\\\"collection\\\",\n",
    "                            \\\"Resource\\\":[\n",
    "                                \\\"collection\\/collection-\"\"\" + agent_id + \"\"\"*\\\"\n",
    "                            ]\n",
    "                        }\n",
    "                    ],\n",
    "                    \\\"AWSOwnedKey\\\":true\n",
    "                }\n",
    "                \"\"\",\n",
    "            type='encryption'\n",
    "        )\n",
    "        print('\\nEncryption policy created:')\n",
    "        print(response)\n",
    "    except botocore.exceptions.ClientError as error:\n",
    "        if error.response['Error']['Code'] == 'ConflictException':\n",
    "            print(\n",
    "                '[ConflictException] The policy name or rules conflict with an existing policy.')\n",
    "        else:\n",
    "            raise error\n",
    "\n",
    "\n",
    "def create_network_policy(agent_id):\n",
    "    \"\"\"Creates a network policy that matches all collections beginning with collection-\"\"\" + agent_id + \"\"\"\"\"\"\n",
    "    try:\n",
    "        response = opensearch_serverless_client.create_security_policy(\n",
    "            description=f'Network policy created by an agent with id {agent_id}.',\n",
    "            name=f'agent-{agent_id}-policy',\n",
    "            policy=\"\"\"\n",
    "                [{\n",
    "                    \\\"Description\\\":\\\"Public access for the collection created by an agent with id \"\"\" + agent_id +\"\"\".\\\",\n",
    "                    \\\"Rules\\\":[\n",
    "                        {\n",
    "                            \\\"ResourceType\\\":\\\"dashboard\\\",\n",
    "                            \\\"Resource\\\":[\\\"collection\\/collection-\"\"\" + agent_id + \"\"\"*\\\"]\n",
    "                        },\n",
    "                        {\n",
    "                            \\\"ResourceType\\\":\\\"collection\\\",\n",
    "                            \\\"Resource\\\":[\\\"collection\\/collection-\"\"\" + agent_id + \"\"\"*\\\"]\n",
    "                        }\n",
    "                    ],\n",
    "                    \\\"AllowFromPublic\\\":true\n",
    "                }]\n",
    "                \"\"\",\n",
    "            type='network'\n",
    "        )\n",
    "        print('\\nNetwork policy created:')\n",
    "        print(response)\n",
    "    except botocore.exceptions.ClientError as error:\n",
    "        if error.response['Error']['Code'] == 'ConflictException':\n",
    "            print(\n",
    "                '[ConflictException] A network policy with this name already exists.')\n",
    "        else:\n",
    "            raise error\n",
    "\n",
    "\n",
    "def create_access_policy(account_id,\n",
    "                         agent_id,\n",
    "                         lambda_role_arn, \n",
    "                         knowledge_base_role_arn,\n",
    "                         account_iam_role):\n",
    "    \"\"\"Creates a data access policy that matches all collections beginning with agent-\"\"\" + agent_id + \"\"\"\"\"\"\n",
    "    try:\n",
    "        response = opensearch_serverless_client.create_access_policy(\n",
    "            description=f'Data access policy for collections created by an agent with id {agent_id}.',\n",
    "            name=f'agent-{agent_id}-policy',\n",
    "            policy=\"\"\"\n",
    "                [{\n",
    "                    \\\"Rules\\\":[\n",
    "                        {\n",
    "                            \\\"Resource\\\":[\n",
    "                                \\\"index\\/collection-\"\"\" + agent_id + \"\"\"*\\/*\\\"\n",
    "                            ],\n",
    "                            \\\"Permission\\\":[\n",
    "                                \\\"aoss:CreateIndex\\\",\n",
    "                                \\\"aoss:DeleteIndex\\\",\n",
    "                                \\\"aoss:UpdateIndex\\\",\n",
    "                                \\\"aoss:DescribeIndex\\\",\n",
    "                                \\\"aoss:ReadDocument\\\",\n",
    "                                \\\"aoss:WriteDocument\\\"\n",
    "                            ],\n",
    "                            \\\"ResourceType\\\": \\\"index\\\"\n",
    "                        },\n",
    "                        {\n",
    "                            \\\"Resource\\\":[\n",
    "                                \\\"collection\\/collection-\"\"\" + agent_id + \"\"\"*\\\"\n",
    "                            ],\n",
    "                            \\\"Permission\\\":[\n",
    "                                \\\"aoss:CreateCollectionItems\\\",\n",
    "                                \\\"aoss:DescribeCollectionItems\\\",\n",
    "                                \\\"aoss:DeleteCollectionItems\\\",\n",
    "                                \\\"aoss:UpdateCollectionItems\\\"\n",
    "                            ],\n",
    "                            \\\"ResourceType\\\": \\\"collection\\\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \\\"Principal\\\": [\n",
    "                        \\\"\"\"\" + knowledge_base_role_arn + \"\"\"\\\", \n",
    "                        \\\"\"\"\" + account_iam_role + \"\"\"\\\"\n",
    "                    ]\n",
    "                }]\n",
    "                \"\"\",\n",
    "            type='data'\n",
    "        )\n",
    "        print('\\nAccess policy created:')\n",
    "        print(response)\n",
    "    except botocore.exceptions.ClientError as error:\n",
    "        if error.response['Error']['Code'] == 'ConflictException':\n",
    "            print(\n",
    "                '[ConflictException] An access policy with this name already exists.')\n",
    "        else:\n",
    "            raise error\n",
    "\n",
    "\n",
    "def create_collection(agent_id):\n",
    "    \"\"\"Creates a collection\"\"\"\n",
    "    try:\n",
    "        response = opensearch_serverless_client.create_collection(\n",
    "            name=f'collection-{agent_id}',\n",
    "            description=f'Collection created by an agent with id {agent_id}.',\n",
    "            type='VECTORSEARCH'\n",
    "        )\n",
    "        return(response['createCollectionDetail']['arn'])\n",
    "    except botocore.exceptions.ClientError as error:\n",
    "        if error.response['Error']['Code'] == 'ConflictException':\n",
    "            print(\n",
    "                '[ConflictException] A collection with this name already exists. Try another name.')\n",
    "        else:\n",
    "            raise error\n",
    "\n",
    "\n",
    "def wait_for_collection_creation(awsauth,\n",
    "                                 agent_id,\n",
    "                                 vector_index_name, \n",
    "                                 text_field, \n",
    "                                 bedrock_metadata_field,\n",
    "                                 vector_field_name):\n",
    "    \"\"\"Waits for the collection to become active\"\"\"\n",
    "    response = opensearch_serverless_client.batch_get_collection(\n",
    "        names=[f'collection-{agent_id}'])\n",
    "    # Periodically check collection status\n",
    "    while (response['collectionDetails'][0]['status']) == 'CREATING':\n",
    "        print('Creating collection...')\n",
    "        time.sleep(30)\n",
    "        response = opensearch_serverless_client.batch_get_collection(\n",
    "            names=[f'collection-{agent_id}'])\n",
    "    print('\\nCollection successfully created:')\n",
    "    print(response[\"collectionDetails\"])\n",
    "    # Extract the collection endpoint from the response\n",
    "    host = (response['collectionDetails'][0]['collectionEndpoint'])\n",
    "    final_host = host.replace(\"https://\", \"\")\n",
    "    index_data(host=final_host, \n",
    "               awsauth=awsauth, \n",
    "               vector_index_name=vector_index_name,\n",
    "               bedrock_metadata_field=bedrock_metadata_field,\n",
    "               text_field=text_field,\n",
    "               vector_field_name=vector_field_name)\n",
    "\n",
    "\n",
    "def index_data(host, awsauth, vector_index_name, text_field, \n",
    "               bedrock_metadata_field, vector_field_name):\n",
    "    \"\"\"Create an index\"\"\"\n",
    "    # Build the OpenSearch client\n",
    "    client = OpenSearch(\n",
    "        hosts=[{'host': host, 'port': 443}],\n",
    "        http_auth=awsauth,\n",
    "        use_ssl=True,\n",
    "        verify_certs=True,\n",
    "        connection_class=RequestsHttpConnection,\n",
    "        timeout=300\n",
    "    )\n",
    "    # It can take up to a minute for data access rules to be enforced\n",
    "    time.sleep(45)\n",
    "    \n",
    "    # Create index\n",
    "    body = {\n",
    "      \"mappings\": {\n",
    "        \"properties\": {\n",
    "          f\"{bedrock_metadata_field}\": {\n",
    "            \"type\": \"text\",\n",
    "            \"index\": False\n",
    "          },\n",
    "          \"id\": {\n",
    "            \"type\": \"text\",\n",
    "            \"fields\": {\n",
    "            \"keyword\": {\n",
    "              \"type\": \"keyword\",\n",
    "              \"ignore_above\": 256\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          f\"{text_field}\": {\n",
    "            \"type\": \"text\",\n",
    "            \"index\": False\n",
    "          },\n",
    "          f\"{vector_field_name}\": {\n",
    "            \"type\": \"knn_vector\",\n",
    "            \"dimension\": 1536,\n",
    "            \"method\": {\n",
    "              \"engine\": \"nmslib\",\n",
    "              \"space_type\": \"cosinesimil\",\n",
    "              \"name\": \"hnsw\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"settings\": {\n",
    "        \"index\": {\n",
    "          \"number_of_shards\": 2,\n",
    "          \"knn.algo_param\": {\n",
    "            \"ef_search\": 512\n",
    "          },\n",
    "          \"knn\": True,\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    response = client.indices.create(index=vector_index_name, body=body)\n",
    "    print('\\nCreating index:')\n",
    "    print(response)\n",
    "    \n",
    "\n",
    "def create_allow_bedrock_iam_policy(policy_name, agent_id):\n",
    "    \n",
    "    bedrock_allow_models_policy = \"\"\"{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "      {\n",
    "        \"Effect\": \"Allow\",\n",
    "        \"Action\": [\n",
    "          \"bedrock:InvokeModel\",\n",
    "          \"bedrock:ListCustomModels\",\n",
    "          \"bedrock:ListFoundationModels\"\n",
    "        ],\n",
    "        \"Resource\": \"*\"\n",
    "      }\n",
    "    ]\n",
    "    }\"\"\"\n",
    "    \n",
    "    policy = iam.create_policy(\n",
    "            PolicyName=policy_name,\n",
    "            Description=f\"Policy for Bedrock Invoke Model, List Models and ListFoundationModels create by an agent with id {agent_id}.\",\n",
    "            PolicyDocument=bedrock_allow_models_policy,\n",
    "        )\n",
    "        \n",
    "    return policy['Policy']['Arn']\n",
    "    \n",
    "    \n",
    "def create_allow_collection_access(policy_name, collection_arn, agent_id):\n",
    "    \n",
    "    collection_allow_access_policy = \"\"\"{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "      {\n",
    "        \"Effect\": \"Allow\",\n",
    "        \"Action\": [\n",
    "          \"aoss:APIAccessAll\"\n",
    "         ],\n",
    "         \"Resource\": [\n",
    "           \\\"\"\"\" + collection_arn + \"\"\"\\\"\n",
    "         ]\n",
    "      }\n",
    "    ]\n",
    "    }\"\"\"\n",
    "    \n",
    "    policy = iam.create_policy(\n",
    "            PolicyName=policy_name,\n",
    "            Description=f\"Policy for access to the Opensearch by the Knowledge Base created by an agent with id {agent_id}.\",\n",
    "            PolicyDocument=collection_allow_access_policy,\n",
    "        )\n",
    "        \n",
    "    return policy['Policy']['Arn']\n",
    "\n",
    "    \n",
    "def create_knowledge_base_iam_role(role_name, account_id, region):\n",
    "  \n",
    "    basic_role = \"\"\"{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": \"bedrock.amazonaws.com\"\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\",\n",
    "      \"Condition\": {\n",
    "        \"StringEquals\": {\n",
    "          \"aws:SourceAccount\": \\\"\"\"\" + account_id + \"\"\"\\\"\n",
    "        },\n",
    "        \"ArnLike\": {\n",
    "          \"AWS:SourceArn\": \\\"arn:aws:bedrock:\"\"\" + region + \"\"\":\"\"\" + account_id + \"\"\":knowledge-base/*\\\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    ]\n",
    "    }\"\"\"\n",
    "  \n",
    "    iam.create_role(RoleName=role_name, \n",
    "      AssumeRolePolicyDocument=basic_role)\n",
    "\n",
    "    # This role has the AmazonOpenSearchServiceReadOnlyAccess managed policy.\n",
    "    iam.attach_role_policy(RoleName=role_name, \n",
    "      PolicyArn='arn:aws:iam::aws:policy/AmazonOpenSearchServiceReadOnlyAccess')\n",
    "    # This role has the AmazonS3ReadOnlyAccess managed policy.\n",
    "    iam.attach_role_policy(RoleName=role_name,\n",
    "      PolicyArn='arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess')\n",
    "      \n",
    "    return iam.get_role(RoleName=role_name)['Role']['Arn']\n",
    "    \n",
    "    \n",
    "def attach_bedrock_and_collection_policies(role_name,\n",
    "                                           bedrock_policy_arn,\n",
    "                                           collection_policy_arn):\n",
    "    \n",
    "    iam.attach_role_policy(RoleName=role_name,\n",
    "      PolicyArn=bedrock_policy_arn)\n",
    "    iam.attach_role_policy(RoleName=role_name,\n",
    "      PolicyArn=collection_policy_arn)\n",
    "      \n",
    "    return\n",
    "    \n",
    "    \n",
    "def create_knowledge_base(collection_arn, \n",
    "                          vector_field_name,\n",
    "                          vector_index_name,\n",
    "                          knowledge_base_role_arn,\n",
    "                          text_field,\n",
    "                          bedrock_metadata_field,\n",
    "                          agent_id):\n",
    "    \n",
    "    knowledge_base_config = {\n",
    "      \"type\": \"VECTOR\",\n",
    "      \"vectorKnowledgeBaseConfiguration\": {\n",
    "        \"embeddingModelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1\"\n",
    "      }\n",
    "    }\n",
    "\n",
    "    storage_config = {\n",
    "      \"opensearchServerlessConfiguration\": {\n",
    "        \"collectionArn\": collection_arn, \n",
    "        \"fieldMapping\": {\n",
    "          \"metadataField\": bedrock_metadata_field,\n",
    "          \"textField\": text_field,  \n",
    "          \"vectorField\": vector_field_name\n",
    "        },\n",
    "        \"vectorIndexName\": vector_index_name\n",
    "      },\n",
    "      \"type\": \"OPENSEARCH_SERVERLESS\" \n",
    "    }\n",
    "\n",
    "    response = agent_client.create_knowledge_base(\n",
    "        name=f'Agent-{agent_id}-KnowledgeBase-Opensearch',\n",
    "        description=f'Knowledge base created by an agent with id {agent_id}.',\n",
    "        roleArn=knowledge_base_role_arn,\n",
    "        knowledgeBaseConfiguration=knowledge_base_config,\n",
    "        storageConfiguration=storage_config)\n",
    "        \n",
    "    return(response['knowledgeBase']['knowledgeBaseId'])\n",
    "\n",
    "\n",
    "def create_data_source(knowledge_base_id, s3_bucket_name, agent_id):\n",
    "    \n",
    "    # Set up bucket arn from user's 's3_bucket_name'\n",
    "    s3_bucket_arn = f'arn:aws:s3:::{s3_bucket_name}'\n",
    "    \n",
    "    data_source_configuration = {\n",
    "      \"s3Configuration\": {\n",
    "        \"bucketArn\": s3_bucket_arn\n",
    "      },\n",
    "        \"type\": \"S3\"\n",
    "    }\n",
    "    \n",
    "    response = agent_client.create_data_source(\n",
    "        knowledgeBaseId=knowledge_base_id,\n",
    "        name=f'Agent-{agent_id}-DataSource',\n",
    "        dataSourceConfiguration=data_source_configuration)\n",
    "        \n",
    "    return response['dataSource']['dataSourceId']\n",
    "    \n",
    "    \n",
    "def associate_knowledge_base(agent_id, knowledge_base_id):\n",
    "    \n",
    "    agent_kb_description = agent_client.associate_agent_knowledge_base(\n",
    "    agentId=agent_id,\n",
    "    agentVersion='DRAFT',\n",
    "    description='Modify this instruction as needed.',\n",
    "    knowledgeBaseId=knowledge_base_id\n",
    ")\n",
    "    \n",
    "    return agent_kb_description\n",
    "\n",
    "def start_ingestion_job(knowledge_base_id, dataSourceId):\n",
    "    response = agent_client.start_ingestion_job(\n",
    "        knowledgeBaseId=knowledge_base_id,\n",
    "        dataSourceId=dataSourceId\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_id = random.randint(0,1000)\n",
    "\n",
    "# Get role to attach to Opensearch allow list\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "# Get account id and current region\n",
    "account_id = role.split(\":\")[4]\n",
    "print(account_id)\n",
    "region = os.environ['AWS_REGION']\n",
    "print(region)\n",
    "\n",
    "# specify bucket with data to index for RAG\n",
    "s3_bucket_name = 'sagemaker-studio-' + str(account_id) # \"sagemaker-studio-XXX\" \n",
    "\n",
    "# Set up auth for Opensearch client\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key,\n",
    "               region, service, session_token=credentials.token)\n",
    "\n",
    "agent_id_lowercase = str(random_id) #.lower() # To satisfy collection policy name constraints\n",
    "bedrock_policy_name = f\"bedrock-policy-name-created-by-agent-{random_id}\"\n",
    "collection_policy_name = f\"collection-policy-name-created-by-agent-{random_id}\"\n",
    "knowledge_base_role_name = f\"AmazonBedrockExecutionRoleForKnowledgeBase_{random_id}\"\n",
    "vector_field_name = f\"embeddings-{agent_id_lowercase}\"\n",
    "vector_index_name = f\"vector-{agent_id_lowercase}\"\n",
    "text_field = \"text-field\"\n",
    "bedrock_metadata_field = \"bedrock-managed-metadata-field\"\n",
    "\n",
    "knowledge_base_role_arn = create_knowledge_base_iam_role(knowledge_base_role_name, account_id, region)\n",
    "print(knowledge_base_role_arn)\n",
    "create_encryption_policy(agent_id=agent_id_lowercase)\n",
    "create_network_policy(agent_id=agent_id_lowercase)\n",
    "create_access_policy(account_id=account_id,\n",
    "                     agent_id=agent_id_lowercase,\n",
    "                     lambda_role_arn=role, \n",
    "                     knowledge_base_role_arn=knowledge_base_role_arn,\n",
    "                     account_iam_role=role)\n",
    "\n",
    "collection_arn = create_collection(agent_id=agent_id_lowercase)\n",
    "wait_for_collection_creation(awsauth=awsauth, \n",
    "                             agent_id=agent_id_lowercase,\n",
    "                             vector_index_name=vector_index_name,\n",
    "                             text_field=text_field,\n",
    "                             bedrock_metadata_field=bedrock_metadata_field,\n",
    "                             vector_field_name=vector_field_name)\n",
    "\n",
    "bedrock_policy_arn = create_allow_bedrock_iam_policy(policy_name=bedrock_policy_name,\n",
    "                                                     agent_id=random_id)\n",
    "collection_policy_arn = create_allow_collection_access(policy_name=collection_policy_name, \n",
    "                                                       collection_arn=collection_arn,\n",
    "                                                       agent_id=random_id)\n",
    "\n",
    "# Pause to make sure iam policies are created                           \n",
    "time.sleep(10)                                                       \n",
    "\n",
    "attach_bedrock_and_collection_policies(role_name=knowledge_base_role_name,\n",
    "                                       collection_policy_arn=collection_policy_arn,\n",
    "                                       bedrock_policy_arn=bedrock_policy_arn)\n",
    "\n",
    "# Pause to make sure iam policies are attached                           \n",
    "time.sleep(10)\n",
    "\n",
    "knowledge_base_id = create_knowledge_base(collection_arn=collection_arn, \n",
    "                                          vector_field_name=vector_field_name,\n",
    "                                          vector_index_name=vector_index_name,\n",
    "                                          knowledge_base_role_arn=knowledge_base_role_arn,\n",
    "                                          text_field=text_field,\n",
    "                                          bedrock_metadata_field=bedrock_metadata_field,\n",
    "                                          agent_id=random_id)\n",
    "print(knowledge_base_id)\n",
    "datasource_id = create_data_source(knowledge_base_id=knowledge_base_id,\n",
    "                   s3_bucket_name=s3_bucket_name,\n",
    "                   agent_id=random_id)\n",
    "\n",
    "print(datasource_id)\n",
    "def start_ingestion_job(knowledge_base_id, dataSourceId):\n",
    "    response = agent_client.start_ingestion_job(\n",
    "        knowledgeBaseId=knowledge_base_id,\n",
    "        dataSourceId=dataSourceId\n",
    "    )\n",
    "    return response\n",
    "\n",
    "response = start_ingestion_job(knowledge_base_id, datasource_id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config)\n",
    "\n",
    "model_id = \"anthropic.claude-instant-v1\" # try with both claude instant as well as claude-v2. for claude v2 - \"anthropic.claude-v2\"\n",
    "kb_id = knowledge_base_id\n",
    "%store kb_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetreiveAndGenerate API\n",
    "Behind the scenes, `RetrieveAndGenerate` API converts queries into embeddings, searches the knowledge base, and then augments the foundation model prompt with the search results as context information and returns the FM-generated response to the question. For multi-turn conversations, Knowledge Bases manage short-term memory of the conversation to provide more contextual results. \n",
    "\n",
    "The output of the `RetrieveAndGenerate` API includes the   `generated response`, `source attribution` as well as the `retrieved text chunks`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveAndGenerate(input, kbId, sessionId=None, model_id = \"anthropic.claude-instant-v1\"):\n",
    "    model_arn = f'arn:aws:bedrock:us-east-1::foundation-model/{model_id}'\n",
    "    if sessionId:\n",
    "        return bedrock_agent_client.retrieve_and_generate(\n",
    "            input={\n",
    "                'text': input\n",
    "            },\n",
    "            retrieveAndGenerateConfiguration={\n",
    "                'type': 'KNOWLEDGE_BASE',\n",
    "                'knowledgeBaseConfiguration': {\n",
    "                    'knowledgeBaseId': kbId,\n",
    "                    'modelArn': model_arn\n",
    "                }\n",
    "            },\n",
    "            sessionId=sessionId\n",
    "        )\n",
    "    else:\n",
    "        return bedrock_agent_client.retrieve_and_generate(\n",
    "            input={\n",
    "                'text': input\n",
    "            },\n",
    "            retrieveAndGenerateConfiguration={\n",
    "                'type': 'KNOWLEDGE_BASE',\n",
    "                'knowledgeBaseConfiguration': {\n",
    "                    'knowledgeBaseId': kbId,\n",
    "                    'modelArn': model_arn\n",
    "                }\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query = \"Are Amazon's latest financial results good?\"\n",
    "response = retrieveAndGenerate(query, kb_id,model_id=model_id)\n",
    "generated_text = response['output']['text']\n",
    "pp.pprint(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "         contexts.append(reference[\"content\"][\"text\"])\n",
    "\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "If you want more customized experience, you can use `Retrieve API`. This API converts user queries into embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom workflows on top of the semantic search results. \n",
    "For sample code, try following notebooks: \n",
    "- `customized-rag-retrieve-api-claude-v2.ipynb` - it calls the `retrieve` API to get relevant contexts and then augment the context to the prompt, which you can provide as input to any text-text model provided by Amazon Bedrock. \n",
    "  \n",
    "- You can use the RetrieveQA chain from LangChain and add Knowledge Base as retriever. For sample code, try notebook: \n",
    "`customized-rag-retrieve-api-langchain-claude.ipynb`\n",
    "\n",
    "- If you are interested in evaluating your RAG application, for sample code, try notebook: \n",
    "`customized-rag-retrieve-api-titan-lite-evaluation` where we are using `Amazon Titan Lite` model for generating responses and `Anthropic Claude V2` for evaluating response. \n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
